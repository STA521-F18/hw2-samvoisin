---
title: "HW2 STA521 Fall18"
author: 'Sam Voisin (netid: psv6, github: samvoisin)'
date: "Due September 23, 2018 5pm"
output:
  pdf_document: default
  html_document:
    df_print: paged

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exploratory Data Analysis

```{r data, include = FALSE}
library(alr3)
library(knitr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(car)
data(UN3, package="alr3")

print_na_cols <- function(df) {
  # name data frame columns containing NA values
  na_cols <- c()
  
  for (name in names(UN3)) {
    if (any(is.na(UN3[name]))) {
      na_cols <- c(na_cols, name)
    }
  }
  print(na_cols)
}

```


All data is a quantitative measurement of some sort. `ModernC`, `Change`, `Frate`, and `Purban` are percentages. `Pop` and `Fertility` are counts. `PPgdp` is a continuous quantitative variable (minus the fact that we can't divide beyond a penny). Below, we can see that `ModernC`, `Change`, `PPgdp`, `Frate`, `Pop`, and `Fertility` all contain `NA` values. This leaves Purban as the only column with no NA values.

```{r Question1, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

str(UN3)

print("Columns with NA values:")
print_na_cols(UN3)


```

2. What is the mean and standard deviation of each quantitative predictor?

```{r Question2, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

col_mean <- round(sapply(UN3, mean, na.rm = TRUE), 2)
col_sd <- round(sapply(UN3, sd, na.rm = TRUE), 2)

kable(
  cbind(col_mean, col_sd),
  col.names = c("Mean", "St Dev"),
  format.args = list(decimal.mark = '.', big.mark = ",")
  )

```


3. Investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots
highlighting the relationships among the predictors. Comment
on your findings regarding trying to predict `ModernC` from the other variables.  Are there potential outliers, nonlinear relationships or transformations that appear to be needed based on your graphical EDA?

  As a first step, I used the ggpairs to create a matrix of all of the variables. From the plot matrix, it seems there may be two outliers in `Pop`. Fig. 3.1 below shows these points represent China and India. In Fig. 3.2 the relationship between `PPgdp` and `ModernC` shows the highest density of points centered near the y-axis, and the realtionship appears non-linear. This variable may need to be transformed. The next observation I made from the plot matrix is the near linear relationship `Fertility` has with `ModernC` in Fig. 3.3. It is not surprising that there is a relationship here. However, the near linear nature of the realtionship of the predictor is promising with regards to the linearity assumptions for regression. Finally, `Purban` also has a linear, positive relationship with `ModernC` (Fig. 3.4).

```{r Question3, message = FALSE, warning = FALSE, echo = FALSE, fig.width= 14, fig.height= 10}

UN3_rmna <- UN3[complete.cases(UN3), ]

ggpairs(UN3_rmna)
  
# create Pop vs ModernC plot
PopModc <- ggplot(data = UN3_rmna, aes(x = Pop, y = ModernC)) + 
  geom_point(size = 2.5) +
  ggtitle("Population vs Modern Contraception %") +
  labs(x = "Population (000s)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 3.1") +
  geom_text(aes(label = ifelse(Pop > 1000000, row.names(UN3_rmna),''),
                hjust = 1,
                vjust = 2)) +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
          axis.text = element_text(size = 18))


# create PPgdp vs ModernC plot
PPgdpModc <- ggplot(data = UN3_rmna, aes(x = PPgdp, y = ModernC)) + 
  geom_point(size = 2.5) +
  ggtitle("Per Capita GDP vs Modern Contraception %") +
  labs(x = "Per Capita GDP (USD)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 3.2") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
          axis.text = element_text(size = 18))
  

# create ModernC vs Fertility plot
FertModc <- ggplot(data = UN3_rmna, aes(x = ModernC, y = Fertility)) + 
  geom_point(size = 2.5) +
  ggtitle(" Fertility Rate vs Modern Contraception %") +
  labs(x = "Expected Fertility Rate (# per female)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 3.3") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
          axis.text = element_text(size = 18))


# create ModernC vs Frate
PurbModc <- ggplot(data = UN3_rmna, aes(x = Purban, y = ModernC)) + 
  geom_point(size = 2.5) +
  ggtitle("Urban Population % vs Modern Contraception %") +
  labs(x = "Urban Population (%)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 3.4") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 18))

grid.arrange(PopModc, PPgdpModc, FertModc, PurbModc, ncol = 2)

```

## Model Fitting

4.  Use the `lm()` function to perform a multiple linear regression with `ModernC` as the response and all other variables as the predictors, using the formula `ModernC ~ .`, where the `.` includes all remaining variables in the dataframe.  Create diagnostic residual plot from the linear model object and comment on results regarding assumptions.  How many observations are used in your model fitting?

There were 125 observations used in fitting this preliminary model after removing of incomplete cases.

From the below residual plots we can see a few issues regarding the three assumptions for linear models. First, it seems that the constant variance assumption is incorrect. We can see this in the Residuals vs Fitted and the Scale-Location graphs. Both seem to fan out slightly over the horizontal axis. From the Normal Q-Q plot we can see that the normality assumption begins to break down at the positive end of the normal distribution. Points that theoretically should be in the positive second standard deviation seem to be closer to the first (i.e. the residuals seem to be skewed left). It is worth noting that China and India, while having high leverage, are not outside the contours of Cook's Distance.

```{r Question4, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

PreTMod <- lm(ModernC ~ ., data = UN3_rmna)

par(mfrow=c(2,2))
plot(PreTMod, ask = FALSE)

```

5. Examine added variable plots `car::avPlot` or `car::avPlots`  for your model above. Are there any plots that suggest that transformations are needed for any of the terms in the model? Describe. Is it likely that any of the localities are influential for any of the terms?  Which localities?  Which terms?

As mentioned previously, China and Inda are the highest leverage values in the third graph of column two, ModernC | others vs Pop | others. This means those points are the two most likely outliers.

Notably, the added variable plots for `Purban` and `Frate` have slopes near zero meaning that they do not provide unique information regarding the variation in `ModernC` beyond the other predictors. The summary output below confirms this assessment. The t-statistics for both $\hat\beta$ values are not significant. These predictors will be removed from the model.

```{r Question5, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

summary(PreTMod)

avPlots(PreTMod)

```

6.  Using the Box-Tidwell `car::boxTidwell` or graphical methods find appropriate transformations of the predictor variables to be used as predictors in the linear model.  If any predictors are negative, you may need to transform so that they are non-negative. Describe your method and the resulting transformations.

The first transformation performed was taking the natural log of the `Pop` variable. This brings the data within a single order of magnitude and reduces the leverage of China and India (Fig. 6.1). Next, the Box-Tidwell procedure was performed to test linearity assumptions for the `PPgdp`, `Fertility`, and `Change` predictors. Due to the occasionally negative values of the `Change` predictor, `Change` was shifted in the positive direction via the following formula: $|min(Change)| + 1$. This guarantees the lowest value is $1$ while maintaing the relationship with `ModernC`. the Bonferroni correction used to control the familywise error rate adjusted the significance level to $\alpha = 1.7\%$. The results of the Box-Tidwell test were not significant enough to reject the null $H_0: \lambda = 1$ for `PPgdp` or `Fertility`. The mean-shifted `Change` variable did produce a significant result. However, the maximim likelihood estimate of $\lambda \approx 89$. This result suggests that the Box-Tidwell method should not be used for transforming this variable.

```{r Question6, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

paste("Bonferroni adjustment to 5% significance level (3 hypotheses): alpha =", round(0.05 / 3, 3))

UN3_rmna %>%
  # boxTidwell function cannot take non-pos values
  # shift Change var up by absolute value of min + 1
  mutate(ShiftChange = Change + abs(min(Change)) + 1) %>%
  boxTidwell(ModernC ~ PPgdp + Fertility + ShiftChange,
             other.x = ~ log(Pop),
             verbose = FALSE,
             data = .)

# fit X transformed model
PostXTMod <- lm(ModernC ~ PPgdp + Fertility +
                Change + log(Pop),
                data = UN3_rmna)

PopModc <- ggplot(data = UN3_rmna, aes(x = log(Pop), y = ModernC)) + 
  geom_point(size = 2.5) +
  ggtitle("Log Population vs Modern Contraception %") +
  labs(x = "Log(Population)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 6.1") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
        axis.text = element_text(size=18))

ModcFert <- ggplot(data = UN3_rmna, aes(x = Fertility, y = ModernC)) + 
  geom_point(size = 2.5) +
  ggtitle("Fertility Rate vs Modern Contraception %") +
  labs(x = "Fertility Rate (expected # of children)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 6.2") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
        axis.text = element_text(size=18))

lPPgdpModc <- ggplot(data = UN3_rmna, aes(x = log(PPgdp), y = ModernC)) +
  geom_point(size = 2.5) +
  ggtitle("Per Capita GDP vs Modern Contraception %") +
  labs(x = "Per Capita GDP (USD)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 6.3") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
          axis.text = element_text(size=18))

SChangeModc <- ggplot(data = UN3_rmna,
                      aes(x = Change,
                          y = ModernC)) +
  geom_point(size = 2.5) +
  ggtitle("Population Change vs Modern Contraception %") +
  labs(x = "Population Change (%)",
       y = "Access to Contraception (%)",
       subtitle = "Fig. 6.4") +
  theme(plot.title = element_text(size = 18, face = "bold"),
        axis.title = element_text(size = 17),
          axis.text = element_text(size=18))

grid.arrange(PopModc, ModcFert, lPPgdpModc, SChangeModc, ncol = 2)

```

7. Given the selected transformations of the predictors, select a transformation of the response using `MASS::boxcox` or `car::boxCox` and justify.

The Box-Cox method for estimating the maximum likelihood estimate for a power transformation of the response variable, ModernC, produces the curve below. The closest interpretable values to the $95%$ confidence interval are $\frac{1}{2}$ and $1$. A power transformation of $\lambda = 1$ indicates no transformation is needed. Because there seems to be no indication that a $1/2$ power transformation has a higher likelihood than no transformation it is best to leave the response untransformed for ease of interpretation.

```{r Question7, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

boxCox(PostXTMod)

```

8.  Fit the regression using the transformed variables.  Provide residual plots and added variables plots and comment.  If you feel that you need additional transformations of either the response or predictors, repeat any steps until you feel satisfied.

The added variable plots depict all predictors providing unique information about the variability of `ModernC`. Diagnostic plots of the predictor/ response relationsips are below. There are clear improvements in these diagnostics after removing the variables for which we could not reject $H_0$. Most notably, the Normal Q-Q plot shows a decrease in the leftward skew of residuals and the leverage values of China and India have decreased as intended on the Residuals vs Leverage plot.

```{r Question8, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

avPlots(PostXTMod)

par(mfrow=c(2,2))
plot(PostXTMod, ask = FALSE)


```

9. Start by finding the best transformation of the response and then find transformations of the predictors.  Do you end up with a different model than in 8?

The result of doing the Box-Cox procedure before the Box-Tidwell procedure does not result in a significantly different outcome with regard to theappropriate variable transformations. The only notable difference is that the Confidence interval for the Box-Cox test has moved away from $\lambda = \frac{1}{2}$ and now completely overlaps $\lambda = 1$.

```{r Question9, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

boxCox(PreTMod)

UN3_rmna %>%
  # boxTidwell function cannot take non-pos values
  # shift Change var up by absolute value of min + 1
  mutate(ShiftChange = Change + abs(min(Change)) + 1) %>%
  boxTidwell(ModernC ~ PPgdp + Fertility + ShiftChange,
             other.x = ~ log(Pop),
             verbose = FALSE,
             data = .)

```

10.  Are there any outliers or influential points in the data?  Explain.  If so, refit the model after removing any outliers and comment on residual plots.

There are no outlier points in the data. The result of the Bonferroni corrected T-test of the studentized residuals does not result in any t-statistics which suggest rejecting the null hypothesis $H_0: \mu_i = E[Y|X = x_i]$.

```{r Question10, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

outlierTest(PostXTMod)

ggplot(PostXTMod, aes(x = hatvalues(PostXTMod), y = rstandard(PostXTMod))) + 
  geom_point(size = 4) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("Standardized Residuals vs Leverage") +
  labs(x = "Leverage",
       y = "Standardized Residuals") +
  geom_text(aes(label = ifelse(hatvalues(PostXTMod) > 0.1,
                               names(PostXTMod$resid),
                               ''),
                hjust = 1,vjust = 2)) +
  theme(plot.title = element_text(size = 20, face = "bold"),
        axis.title = element_text(size = 20),
        axis.text = element_text(size=18))

```

## Summary of Results

11. For your final model, provide summaries of coefficients with 95% confidence intervals in a nice table with interpretations of each coefficient.


```{r Question11, echo = FALSE, warning = FALSE, message = FALSE, fig.width= 14, fig.height= 10}

SummDF <- data.frame(Betas = round(PostXTMod$coefficients, 4),
                     LowB = round(ifelse(names(PostXTMod$coefficients) == "log(Pop)",
                                         exp(confint.lm(PostXTMod)[, 1]),
                                         confint.lm(PostXTMod)[, 1]), 4),
                     HighB = round(ifelse(names(PostXTMod$coefficients) == "log(Pop)",
                                         exp(confint.lm(PostXTMod)[, 2]),
                                         confint.lm(PostXTMod)[, 2]), 4),
                     row.names = ifelse(names(PostXTMod$coefficients) == "log(Pop)",
                                              "Pop",
                                              names(PostXTMod$coefficients))
                     )

SummDF

kable(SummDF, col.names = c("Coef. Est.", "2.5%", "97.5%"))

```

Holding all else constant, the interpretation of the above coefficients are:
 * $\hat \beta_{PPgdp}$ - A $100 (USD) incrase in per person gross domestic product is expected to correspond with a $0.06\%$ increase in the availability of modern contraception.
 * $\hat \beta_{Fertility}$ - A country in which the expected fertility rate is greater by one child is expected to also be characterized by a $11.2\%$ decrease in the availability of modern contraception.
 * $\hat \beta_{Change}$ - A country whose population growth rate is $1\%$ higher than another is expected to have a $4.6\%$ greater access to modern contraception.
 * $\hat \beta_{Pop}$ A one percent population increase is expected to correspond to a $0.9\% incrase is the availability of modern contraception.

12. Provide a paragraph summarizing your final model and findings suitable for the US envoy to the UN after adjusting for outliers or influential points. You should provide a justification for any case deletions in your final model


In summary, the final model provides estimates of the factors affecting the variability of the access women from different countries have to modern contraception methods. Using this model the US envoy to the UN can estimate this metric during meetings with colleagues. Additionally, the parameters in the model can be used to infer the relationships between socio-economic factors and a specific issue affecting women in each country. Finally, although correlation does not determine causality, the envoy can use the model to recommend policy decisions to diplomatic partners.


## Methodology

    
13. Prove that the intercept in the added variable scatter plot will always be zero.  _Hint:  use the fact that if $H$ is the project matrix which contains a column of ones, then $1_n^T (I - H) = 0$.  Use this to show that the sample mean of residuals will always be zero if there is an intercept._

Let $X_{(i)}$ be a design matrix of $p - 1$ parameters and $n$ rows by removing column $i$. Then the projection matrix for the added variable regression is

\[
H_{(i)} = X_{(i)} (X_{(i)}^T X_{(i)})^{-1} X_{(i)}^T
\]

$\hat X_{i \dot (i)}$ is used to indicate the fitted values of $E[X_i|X_{(i)}]$.

\[
\begin{align*}
\hat e_{Y|Otheres} &= \hat e_{X_i|Others} \times \hat\beta + \hat \beta_0\\
Y - \hat Y_{(i)} &= X_i - \hat X_{i \dot (i)} \times \hat\beta + \hat \beta_0\\
(I - H_{(i)}) Y &= (I - H_{(i)}) X_i \times \hat\beta + \hat \beta_0\\
\end{align*}
\]

Multiplying the equation by $1_n^T$

\[
\begin{align*}
1_n^T (I - H_{(i)}) Y &= 1_n^T (I - H_{(i)}) X_i \times \hat\beta + 1_n^T \hat \beta_0\\
0 Y &= 0 \times \hat\beta + 1_n^T \hat \beta_0\\
0 &= \hat \beta_0
\end{align*}
\]